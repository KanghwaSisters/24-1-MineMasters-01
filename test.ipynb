{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPijmrTkIJmPDwmw5McA0kf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nvQg1R7G0H3f"},"outputs":[],"source":["class Test_Agent2:\n","    def __init__(self, input_dim, output_dim, model):\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.model = model\n","        self.epsilon = 0.0\n","\n","    def get_action(self, state):\n","\n","        state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n","        with torch.no_grad():\n","            q_values = self.model(state)\n","\n","        action = torch.argmax(q_values, dim=1).item()\n","        return action"]},{"cell_type":"code","source":["def test_model2(model_path, agent, env, num_episodes=10000):\n","    episodes, scores, score_avg, test_action, win_list, win_rate_list = [], [], [], [], [], []\n","    agent.model.load_state_dict(torch.load(model_path))\n","    agent.model.eval()\n","\n","    for epi in range(num_episodes):\n","        done = False\n","        score = 0\n","        test_action_epi = []\n","\n","        state = env.reset()\n","        while not done:\n","            action = agent.get_action(state)\n","            if action not in test_action_epi:\n","              test_action_epi.append(action)\n","              next_state, reward, exploded, done = env.step(action)\n","              score += reward\n","              state = next_state\n","            else:\n","              win_list.append(0)\n","              break\n","\n","        if done:\n","            # win\n","            if not env.exploded:\n","                win_list.append(1)\n","            else:\n","                win_list.append(0)\n","\n","            test_action.append(len(test_action_epi))\n","            episodes.append(epi)\n","            scores.append(score)\n","            score_avg.append(np.mean(scores[-100:]))\n","\n","        if (epi % 100) == 0:\n","\n","          win_rate = np.mean(win_list[-100:]) if len(win_list) >= 100 else np.mean(win_list)\n","          action_avg = np.mean(test_action[-100:]) if len(test_action) >= 100 else np.mean(test_action)\n","          win_rate_list.append(win_rate)\n","          print(f\"Episode: {epi} | Score: {np.median(scores[-100:]):.5f} | Win Rate: {win_rate:.2f} | action_list: {action_avg:.2f}\")\n","\n","    print(f\"Win rate: {np.mean(win_list)} | Standard Deviation: {np.std(win_rate_list)}\")\n","\n","env = MinesweeperEnv()\n","model = NeuralNet(env.height * env.width)\n","agent = Test_Agent2(env.height * env.width, env.height * env.width, model)\n","\n","model_path = '/content/drive/MyDrive/minesweeper_model2.pth'\n","test_model2(model_path, agent, env, num_episodes=10000)"],"metadata":{"id":"pz4_wonp0Lpq"},"execution_count":null,"outputs":[]}]}