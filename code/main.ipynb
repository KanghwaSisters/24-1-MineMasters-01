{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDWnaBo/TGzriDIFTSHTJe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fuzqx9CazBB-"},"outputs":[],"source":["env = MinesweeperEnv()\n","agent = Agent(env.height*env.width, env.height*env.width)\n","\n","EPISODES = 100000\n","\n","episodes, scores, score_avg, total_action, length_memory, win_list = [], [], [], [], [], []\n","\n","for epi in range(EPISODES):\n","    done = False\n","    score = 0\n","    total_action_epi = []\n","\n","    # 게임 다시 시작; 게임판 초기화\n","    state = env.reset()\n","    while not done:\n","\n","        # 현재 상태를 기반으로 행동을 선택\n","        action = agent.get_action(state)\n","        total_action_epi.append(action)\n","        next_state, reward, exploded, done = env.step(action)\n","        score += reward\n","        agent.append_sample(state, action, next_state, reward, exploded, done)\n","\n","        # memory의 길이가 최소 이상일 때 훈련\n","        # batch_size만큼의 데이터가 훈련\n","        if len(agent.memory) > agent.memory_size_min:\n","            agent.train_model()\n","            if done:\n","              agent.lr_scheduler.step()\n","\n","        state = next_state\n","\n","        if done:\n","\n","          if not env.exploded:\n","              win_list.append(1)\n","          else:\n","              win_list.append(0)\n","\n","          if (epi % agent.update_time) == 0:\n","              agent.update_target_model()\n","\n","          total_action.append(len(total_action_epi))\n","          episodes.append(epi)\n","          scores.append(score)\n","          score_avg.append(np.mean(scores[-100:]))\n","          length_memory.append(len(agent.memory))\n","\n","          if (epi % 100) == 0:\n","              win_rate = np.mean(win_list[-100:]) if len(win_list) >= 100 else np.mean(win_list) # -100이므로 마지막에서 100번째 최신 것을 반영함.\n","              loss_avg = np.mean(agent.loss_list[-100:]) if len(win_list) >= 100 else np.mean(win_list)\n","              action_avg = np.mean(total_action[-100:]) if len(total_action) >= 100 else np.mean(total_action)\n","              print(f\"Episode: {epi} | Score: {np.median(scores[-100:]):.5f} | Epsilon: {agent.epsilon:.2f} | Win Rate: {win_rate}, Loss avg: {loss_avg:.5f} | action_list: {action_avg}\")"]}]}
